#!/usr/bin/env bash

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
source $DIR/functions.sh

hdtfile=$1
mapping=$2
outputfile=$3
outputfile2=/dev/null

# Creating file names
fd1=$(mktemp -u)
fd2=$(mktemp -u)
fd3=$(mktemp -u)
fd4=$(mktemp -u)
fd5=$(mktemp -u)
fd6=$(mktemp -u)
fd7=$(mktemp -u)

#p1=$(mkfifo $fd1)
#p2=$(mkfifo $fd2)
#p3=$(mkfifo $fd3)
#p4=$(mkfifo $fd4)
#p5=$(mkfifo $fd5)
#p6=$(mkfifo $fd6)
#p7=$(mkfifo $fd7)

# Read knowledge graph and classify triples accordingly
lbzcat $mapping \
  | get_name \
  | awk -v p=$prefix '{print p $0" ? ?"}' \
  | parallel --pipe -j$proc --round-robin hdtSearch $hdtfile 2>/dev/null \
  | parallel --pipe -j$proc --round-robin \
    awk -F \' \' \'$awk_prog_2 \' \
  | parallel --pipe -j$proc --round-robin \
    awk -F \'$sep\' -v p=$prefix \'$awk_prog_3 \' \
  | lbzip2 -zc > $fd1

# Classify triples and parse
lbzcat $fd1 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -v l=$label -v n=$name \'$awk_prog_4 \' \
  | LC_ALL=C sort -S$mem --parallel $proc2 -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 collapse 3 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -v l=$label -v n=$name -f text/labels_to_json.awk \
  | lbzip2 -zc > $fd2

# Classify literals and parse
lbzcat $fd1 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -v l=$label -v n=$name -f text/classify_literals.awk \
  | LC_ALL=C sort -S$mem --parallel $proc2 -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 collapse 3 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -f text/literals_to_json.awk \
  | lbzip2 -zc > $fd3

# Classify categories and parse
awk -F"$sep" 'NR==FNR {m[$1]=$3;next};{print $1"|"m[$3]"@en"}' \
  <(lbzcat $fd2) <(lbzcat $fd1 | \
              parallel --pipe -j$proc2 --round-robin awk -F \"${sep}\" -v c=$category -f text/classify_categories.awk ) \
  | LC_ALL=C sort -S$mem --parallel $proc -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -v t=\'categories\' -f text/split_datamash.awk \
  | lbzip2 -zc > $fd4

# Classify similar and parse
awk -F'|' 'NR==FNR {m[$1]=$3;next};{print $1"|"m[$3]"@en"}' \
  <(lbzcat $fd2) <(lbzcat $fd1 | \
              parallel --pipe -j$proc2 --round-robin awk -F \"${sep}\" -v d=$disambiguates -v r=$redirects -v s=$sameas -f text/classify_similar.awk ) \
  | LC_ALL=C sort -S$mem --parallel $proc -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -v t=\'similar\' -f text/split_datamash.awk \
  | lbzip2 -zc > $fd5

# Classify related and parse
awk -F'|' 'NR==FNR {m[$1]=$3;next};{print $1"|"$2"|"m[$3]"@en"}' \
  <(lbzcat $fd2) <(lbzcat $fd1 | \
              parallel --pipe -j$proc2 --round-robin awk -F \"${sep}\" -v c=$category -v s=$sameas -v r=$redirects -v d=$disambiguates -f text/classify_related.awk ) \
  | LC_ALL=C sort -S$mem --parallel $proc -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 collapse 3 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -f text/split_related.awk \
  | lbzip2 -zc > $fd6

# Create documents
lbzcat $fd2 $fd3 $fd4 $fd5 $fd6 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' \'$awk_prog_5 \' \
  | LC_ALL=C sort -S$mem --parallel $proc -t"$sep" -k1,1 \
  | datamash -t"$sep" -g 1 collapse 2 collapse 3 \
  | parallel --pipe -j$proc2 --round-robin awk -F \'$sep\' -f text/split_document.awk \
  | lbzip2 -zc | tee $fd7 > $outputfile2

# Flattend documents
lbzcat $fd7 \
  | parallel --pipe -j$proc --round-robin jq -cM -f text/flatten_json.jq \
  | lbzip2 -zc > $outputfile

# Remove fifos
#rm $fd1 $fd2 $fd3 $fd4 $fd5 $fd6 $fd8
